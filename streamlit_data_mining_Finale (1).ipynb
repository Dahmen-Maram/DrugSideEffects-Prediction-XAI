{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QQrstGhJEd8m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "774c14a0-c8e4-48b8-b922-9da1d0a444cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Installer les d√©pendances\n",
        "!pip install streamlit ultralytics pyngrok transformers pillow --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsoJOSr4EnQY",
        "outputId": "f4db0ff8-b9ed-4d16-b88b-a38c78aa115c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Remplace TON_AUTHTOKEN_ICI par ton token ngrok\n",
        "!ngrok authtoken 2vdJFZExAVhUhUeOJZjhTHOLFhG_3noX2p3A3rDQ3KYjAKFgF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3b2me4LE2AF",
        "outputId": "9e91090e-fca1-406a-bf7e-35f6c1394c9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üéØ Application accessible √†: NgrokTunnel: \"https://6708a0f459de.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ],
      "source": [
        "# Installation des d√©pendances\n",
        "!pip install --quiet streamlit ultralytics transformers torch pillow pyngrok scikit-learn==1.7.2 xgboost\n",
        "\n",
        "# V√©rifier que le fichier mod√®le est pr√©sent\n",
        "import os\n",
        "if not os.path.exists(\"/content/blender_final_per_label_thresholds (1).pkl\"):\n",
        "    print(\"‚ö†Ô∏è  Fichier mod√®le non trouv√©, l'application fonctionnera en mode d√©monstration\")\n",
        "\n",
        "# Lancer Streamlit\n",
        "from pyngrok import ngrok\n",
        "import threading\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "def run_streamlit():\n",
        "    subprocess.run([\"streamlit\", \"run\", \"streamlit_app.py\", \"--server.port\", \"8501\", \"--server.address\", \"0.0.0.0\"])\n",
        "\n",
        "# D√©marrer dans un thread\n",
        "thread = threading.Thread(target=run_streamlit)\n",
        "thread.daemon = True\n",
        "thread.start()\n",
        "\n",
        "time.sleep(8)  # Attendre que Streamlit d√©marre\n",
        "\n",
        "# Cr√©er le tunnel ngrok\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"üéØ Application accessible √†: {public_url}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SX1j93Jv7yQ",
        "outputId": "d4c8fe9d-5c91-4b54-a5b7-3ee88b57ed67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 403M Oct 17 22:19 'blender_final_per_label_thresholds (1).pkl'\n"
          ]
        }
      ],
      "source": [
        "!ls -lh \"blender_final_per_label_thresholds (1).pkl\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile streamlit_app.py\n",
        "import streamlit as st\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image, ImageDraw\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import re\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "import base64\n",
        "import torch\n",
        "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
        "import cv2\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer\n",
        "#VERSION FINALE\n",
        "# --- D√âFINITION DE LA CLASSE FIXEDBLENDINGPREDICTOR ---\n",
        "class FixedBlendingPredictor:\n",
        "    def __init__(self):\n",
        "        self.base_models = {}\n",
        "        self.meta_model = None\n",
        "        self.feature_names = None\n",
        "        self.top_drugs = None\n",
        "        self.top_reactions = None\n",
        "        self.per_label_thresholds = None\n",
        "\n",
        "    def create_base_models(self):\n",
        "        from sklearn.ensemble import RandomForestClassifier\n",
        "        from sklearn.linear_model import LogisticRegression\n",
        "        from sklearn.multiclass import OneVsRestClassifier\n",
        "        import xgboost as xgb\n",
        "\n",
        "        self.base_models = {\n",
        "            'xgb1': OneVsRestClassifier(xgb.XGBClassifier(n_estimators=100, max_depth=8, learning_rate=0.1, random_state=42), n_jobs=-1),\n",
        "            'rf1': OneVsRestClassifier(RandomForestClassifier(n_estimators=100, max_depth=15, random_state=44, n_jobs=-1), n_jobs=-1),\n",
        "            'lr1': OneVsRestClassifier(LogisticRegression(C=1.0, penalty='l2', solver='liblinear', max_iter=1000, random_state=46), n_jobs=-1),\n",
        "        }\n",
        "\n",
        "    def train_base_models(self, X_train, y_train):\n",
        "        from tqdm import tqdm\n",
        "        for name, model in tqdm(self.base_models.items(), desc='Training base models'):\n",
        "            try:\n",
        "                model.fit(X_train, y_train)\n",
        "            except Exception as e:\n",
        "                print(f\"Erreur entra√Ænement {name}: {e}\")\n",
        "\n",
        "    def create_meta_features(self, X, batch_size=1000):\n",
        "        import time\n",
        "        import math\n",
        "        meta_features = []\n",
        "        n_samples = X.shape[0]\n",
        "        for name, model in self.base_models.items():\n",
        "            parts = []\n",
        "            for start in range(0, n_samples, batch_size):\n",
        "                end = min(start + batch_size, n_samples)\n",
        "                X_batch = X.iloc[start:end] if hasattr(X, 'iloc') else X[start:end]\n",
        "                probas_batch = model.predict_proba(X_batch)\n",
        "                parts.append(probas_batch)\n",
        "            meta_features.append(np.vstack(parts))\n",
        "        return np.hstack(meta_features)\n",
        "\n",
        "    def train_meta_model(self, X_train, y_train):\n",
        "        import xgboost as xgb\n",
        "        X_meta = self.create_meta_features(X_train)\n",
        "        self.meta_model = xgb.XGBClassifier(n_estimators=50, max_depth=4, learning_rate=0.1, random_state=49)\n",
        "        self.meta_model.fit(X_meta, y_train)\n",
        "\n",
        "    def predict_proba_blended(self, X):\n",
        "        X_meta = self.create_meta_features(X)\n",
        "        return self.meta_model.predict_proba(X_meta)\n",
        "\n",
        "    def predict(self, X, threshold=0.05, min_predictions=5):\n",
        "        probabilities = self.predict_proba_blended(X)\n",
        "        if self.per_label_thresholds is None:\n",
        "            preds = (probabilities > threshold).astype(int)\n",
        "        else:\n",
        "            preds = (probabilities > self.per_label_thresholds[np.newaxis, :]).astype(int)\n",
        "\n",
        "        if min_predictions is not None and min_predictions > 0:\n",
        "            n_samples, n_labels = probabilities.shape\n",
        "            for i in range(n_samples):\n",
        "                if preds[i].sum() >= min_predictions:\n",
        "                    continue\n",
        "                sorted_idx = np.argsort(-probabilities[i])\n",
        "                for idx in sorted_idx:\n",
        "                    if preds[i, idx] == 0:\n",
        "                        preds[i, idx] = 1\n",
        "                    if preds[i].sum() >= min_predictions:\n",
        "                        break\n",
        "        return preds, probabilities\n",
        "\n",
        "# --- Configuration de la page ---\n",
        "st.set_page_config(page_title=\"D√©tection M√©dicaments & Effets Secondaires\", layout=\"wide\")\n",
        "\n",
        "# --- 1Ô∏è‚É£ Charger le mod√®le de pr√©diction d'effets secondaires ---\n",
        "@st.cache_resource\n",
        "def load_side_effect_model():\n",
        "    try:\n",
        "        model_path = \"/content/drive/MyDrive/blender_final_per_label_thresholds (1).pkl\"\n",
        "        saved = joblib.load(model_path)\n",
        "        blender = saved['predictor']\n",
        "        return blender\n",
        "    except Exception as e:\n",
        "        st.error(f\"Erreur chargement mod√®le effets secondaires: {e}\")\n",
        "\n",
        "        # Cr√©er un mod√®le de d√©monstration si le vrai mod√®le n'est pas disponible\n",
        "        st.warning(\"Cr√©ation d'un mod√®le de d√©monstration...\")\n",
        "        demo_model = FixedBlendingPredictor()\n",
        "        demo_model.top_drugs = ['PARACETAMOL', 'METFORMINE', 'INSULIN', 'ZEPBOUND', 'IBUPROFENE', 'AMOXICILLINE']\n",
        "        demo_model.top_reactions = [\n",
        "            'NAUS√âE', 'MAUX DE T√äTE', 'FATIGUE', 'VERTIGES', 'DIARRH√âE',\n",
        "            'DOULEURS ABDOMINALES', '√âRUPTION CUTAN√âE', 'SOMMOLENCE', 'ANXI√âT√â', 'PALPITATIONS'\n",
        "        ]\n",
        "        demo_model.feature_names = [f\"drug_{drug}\" for drug in demo_model.top_drugs] + ['age', 'sex', 'nb_drugs', 'nb_reactions', 'is_sider']\n",
        "        return demo_model\n",
        "\n",
        "# --- 2Ô∏è‚É£ Charger les mod√®les de vision et OCR ---\n",
        "@st.cache_resource\n",
        "def load_vision_models():\n",
        "    try:\n",
        "        # Charger YOLO\n",
        "        yolo_model = YOLO(\"/content/best.pt\")\n",
        "\n",
        "        # Charger TrOCR pour l'√©criture manuscrite\n",
        "        trocr_processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-large-handwritten\")\n",
        "        trocr_model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-large-handwritten\")\n",
        "\n",
        "        # Charger le mod√®le d'embedding pour la similarit√© s√©mantique\n",
        "        sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "        return yolo_model, trocr_processor, trocr_model, sentence_model\n",
        "    except Exception as e:\n",
        "        st.error(f\"Erreur chargement mod√®les vision/OCR: {e}\")\n",
        "        st.info(\"Mode simulation activ√© pour la d√©tection d'images\")\n",
        "        return None, None, None, None\n",
        "\n",
        "# --- 3Ô∏è‚É£ Extraction OCR avec TrOCR ---\n",
        "def extract_text_with_trocr(_processor, _model, image_crop):\n",
        "    \"\"\"Extrait le texte d'une image crop avec TrOCR\"\"\"\n",
        "    try:\n",
        "        # Redimensionner l'image pour de meilleures performances\n",
        "        if max(image_crop.size) > 512:\n",
        "            image_crop = image_crop.resize((512, 512), Image.Resampling.LANCZOS)\n",
        "\n",
        "        # Pr√©parer l'image pour TrOCR\n",
        "        pixel_values = _processor(images=image_crop, return_tensors=\"pt\").pixel_values\n",
        "\n",
        "        # G√©n√©rer la pr√©diction\n",
        "        with torch.no_grad():\n",
        "            generated_ids = _model.generate(pixel_values, max_length=50)\n",
        "\n",
        "        # D√©coder la pr√©diction\n",
        "        extracted_text = _processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "        return extracted_text.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Erreur OCR: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# --- 4Ô∏è‚É£ NOUVELLE FONCTION : Suppression des dosages ---\n",
        "def remove_dosages(text):\n",
        "    \"\"\"\n",
        "    D√©tecte et supprime les dosages, concentrations et unit√©s de mesure du texte\n",
        "    Retourne le texte nettoy√© et la liste des √©l√©ments supprim√©s\n",
        "    \"\"\"\n",
        "    if not text:\n",
        "        return \"\", []\n",
        "\n",
        "    original_text = text\n",
        "    removed_elements = []\n",
        "\n",
        "    # Pattern pour d√©tecter les dosages avec unit√©s\n",
        "    dosage_patterns = [\n",
        "        # Dosages num√©riques avec unit√©s (500mg, 100g, 50mcg, etc.)\n",
        "        r'\\b\\d+\\s*(?:mg|mcg|Œºg|g|kg|ml|l|mL|UI|IU|U\\.I\\.|¬µg|mci|ci|mmol|meq|%|m?g/ml|m?g/l)\\b',\n",
        "        # Dosages en toutes lettres (100 milligrammes, 50 grammes, etc.)\n",
        "        r'\\b\\d+\\s*(?:milligrammes?|grammes?|microgrammes?|litres?|millilitres?|unit√©s?|pourcent|pour\\s*cent)\\b',\n",
        "        # Combinaisons avec slash (500mg/50mg, 100mg/5ml, etc.)\n",
        "        r'\\b\\d+\\s*(?:mg|mcg|g|ml|l)\\s*/\\s*\\d+\\s*(?:mg|mcg|g|ml|l)\\b',\n",
        "        # Pourcentages (5%, 10%, etc.)\n",
        "        r'\\b\\d+\\s*%\\b',\n",
        "        # Unit√©s de mesure g√©n√©rales (10m, 5l, 20cm, etc.)\n",
        "        r'\\b\\d+\\s*(?:m|cm|mm|km|l|dl|cl|ml|g|dg|cg|mg)\\b',\n",
        "        # Dosages avec points d√©cimaux (12.5mg, 0.5g, etc.)\n",
        "        r'\\b\\d+\\.\\d+\\s*(?:mg|mcg|g|ml|l|UI)\\b'\n",
        "    ]\n",
        "\n",
        "    # Appliquer tous les patterns\n",
        "    for pattern in dosage_patterns:\n",
        "        matches = re.findall(pattern, text, re.IGNORECASE)\n",
        "        for match in matches:\n",
        "            removed_elements.append(match)\n",
        "            text = re.sub(re.escape(match), '', text)\n",
        "\n",
        "    # Nettoyer les espaces multiples et les espaces en d√©but/fin\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    # Feedback de d√©bogage\n",
        "    if removed_elements:\n",
        "        st.info(f\"üîß Nettoyage dosage: '{original_text}' ‚Üí Supprim√©: {removed_elements} ‚Üí R√©sultat: '{text}'\")\n",
        "\n",
        "    return text, removed_elements\n",
        "\n",
        "# --- 5Ô∏è‚É£ Nettoyage am√©lior√© du texte OCR ---\n",
        "def enhanced_clean_medication_text(text):\n",
        "    \"\"\"Nettoyage am√©lior√© du texte d√©tect√©\"\"\"\n",
        "    if not text:\n",
        "        return \"\"\n",
        "\n",
        "    # √âtape 1: Supprimer les dosages en premier\n",
        "    text, removed_dosages = remove_dosages(text)\n",
        "\n",
        "    # Si apr√®s suppression des dosages il ne reste rien, retourner vide\n",
        "    if not text:\n",
        "        return \"\"\n",
        "\n",
        "    # √âtape 2: Convertir en majuscules\n",
        "    text = text.upper()\n",
        "\n",
        "    # √âtape 3: Supprimer les caract√®res sp√©ciaux mais garder les lettres, chiffres et espaces\n",
        "    cleaned = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    # √âtape 4: Corrections OCR am√©lior√©es\n",
        "    corrections = {\n",
        "        '0': 'O', '1': 'I', '3': 'E', '4': 'A', '5': 'S', '6': 'G',\n",
        "        '7': 'T', '8': 'B', '9': 'G', '√á': 'C', '√â': 'E', '√à': 'E',\n",
        "        '√Ä': 'A', '√ô': 'U', '√å': 'I', '√è': 'I', '√ú': 'U', '√ñ': 'O',\n",
        "        '√ë': 'N', '≈í': 'OE', '√Ü': 'AE'\n",
        "    }\n",
        "\n",
        "    for wrong, right in corrections.items():\n",
        "        cleaned = cleaned.replace(wrong, right)\n",
        "\n",
        "    # √âtape 5: Corrections de mots courants\n",
        "    word_corrections = {\n",
        "        'PARACETAMOL': 'PARACETAMOL',\n",
        "        'METFORMIN': 'METFORMINE',\n",
        "        'INSULIN': 'INSULIN',\n",
        "        'IBUPROFEN': 'IBUPROFENE',\n",
        "        'AMOXICILLIN': 'AMOXICILLINE',\n",
        "        'ATORVASTATIN': 'ATORVASTATINE',\n",
        "        'BISOPROLOL': 'BISOPROLOL',\n",
        "        'PAROXETIN': 'PAROXETINE',\n",
        "        'OMEPRAZOLE': 'OMEPRAZOLE',\n",
        "        'DOLIPRANE': 'PARACETAMOL',\n",
        "        'EFFERALGAN': 'PARACETAMOL',\n",
        "        'CLAMOXYL': 'AMOXICILLINE',\n",
        "        'AUGMENTIN': 'AMOXICILLINE',\n",
        "        'GLUCOPHAGE': 'METFORMINE'\n",
        "    }\n",
        "\n",
        "    # Appliquer les corrections de mots\n",
        "    for wrong_word, correct_word in word_corrections.items():\n",
        "        if wrong_word in cleaned:\n",
        "            cleaned = cleaned.replace(wrong_word, correct_word)\n",
        "\n",
        "    # √âtape 6: Supprimer les espaces multiples et les espaces en d√©but/fin\n",
        "    cleaned = re.sub(r'\\s+', ' ', cleaned).strip()\n",
        "\n",
        "    return cleaned\n",
        "\n",
        "# --- 6Ô∏è‚É£ Mapping intelligent des m√©dicaments - VERSION AM√âLIOR√âE ---\n",
        "COMMON_MEDICATIONS = {\n",
        "    # Analg√©siques\n",
        "    'PARACETAMOL': 'PARACETAMOL', 'DOLIPRANE': 'PARACETAMOL', 'EFFERALGAN': 'PARACETAMOL',\n",
        "    'ASPIRINE': 'ASPIRINE', 'ASPEGIC': 'ASPIRINE', 'KARDEGIC': 'ASPIRINE',\n",
        "    'IBUPROFENE': 'IBUPROFENE', 'ADVIL': 'IBUPROFENE', 'NUROFEN': 'IBUPROFENE',\n",
        "\n",
        "    # Antibiotiques\n",
        "    'AMOXICILLINE': 'AMOXICILLINE', 'CLAMOXYL': 'AMOXICILLINE', 'AUGMENTIN': 'AMOXICILLINE',\n",
        "    'PENICILLINE': 'PENICILLINE',\n",
        "\n",
        "    # Cardiologie\n",
        "    'ATORVASTATINE': 'ATORVASTATINE', 'TAHOR': 'ATORVASTATINE',\n",
        "    'BISOPROLOL': 'BISOPROLOL', 'CARDENSIEL': 'BISOPROLOL',\n",
        "\n",
        "    # Diab√®te\n",
        "    'METFORMINE': 'METFORMINE', 'GLUCOPHAGE': 'METFORMINE',\n",
        "    'INSULINE': 'INSULIN', 'INSULIN': 'INSULIN',\n",
        "\n",
        "    # Psychiatrie\n",
        "    'PAROXETINE': 'PAROXETINE', 'DEROXAT': 'PAROXETINE',\n",
        "\n",
        "    # Gastro\n",
        "    'OMEPRAZOLE': 'OMEPRAZOLE', 'MOPRAL': 'OMEPRAZOLE',\n",
        "\n",
        "    # Exemples fournis\n",
        "    'ZEPBOUND': 'ZEPBOUND', 'METFORMIN': 'METFORMINE', 'INSULIN': 'INSULIN'\n",
        "}\n",
        "\n",
        "def find_levenshtein_match(detected_text, known_medications, max_distance_ratio=0.3):\n",
        "    \"\"\"Trouve le meilleur match bas√© sur la distance de Levenshtein\"\"\"\n",
        "    try:\n",
        "        from Levenshtein import distance, ratio\n",
        "\n",
        "        best_match = None\n",
        "        best_ratio = 0\n",
        "\n",
        "        for known_med in known_medications:\n",
        "            # Calculer la similarit√©\n",
        "            similarity_ratio = ratio(detected_text, known_med)\n",
        "\n",
        "            # Prendre le ratio de similarit√© comme m√©trique principale\n",
        "            if similarity_ratio > best_ratio:\n",
        "                best_ratio = similarity_ratio\n",
        "                best_match = known_med\n",
        "\n",
        "        # Appliquer un seuil de similarit√©\n",
        "        if best_ratio >= (1 - max_distance_ratio):\n",
        "            st.info(f\"Match Levenshtein: '{detected_text}' ‚Üí '{best_match}' (similarit√©: {best_ratio:.2f})\")\n",
        "            return best_match\n",
        "\n",
        "        return None\n",
        "\n",
        "    except ImportError:\n",
        "        st.warning(\"Levenshtein non install√©, utilisation de la similarit√© simple\")\n",
        "        return find_simple_string_match(detected_text, known_medications)\n",
        "    except Exception as e:\n",
        "        st.error(f\"Erreur Levenshtein: {e}\")\n",
        "        return find_simple_string_match(detected_text, known_medications)\n",
        "\n",
        "def find_simple_string_match(detected_text, known_medications, threshold=0.7):\n",
        "    \"\"\"Matching simple bas√© sur les caract√®res communs si Levenshtein n'est pas disponible\"\"\"\n",
        "    best_match = None\n",
        "    best_similarity = 0\n",
        "\n",
        "    for known_med in known_medications:\n",
        "        # Similarit√© bas√©e sur les caract√®res communs\n",
        "        set1, set2 = set(detected_text.upper()), set(known_med.upper())\n",
        "        common_chars = set1 & set2\n",
        "        similarity = len(common_chars) / max(len(set1), len(set2)) if max(len(set1), len(set2)) > 0 else 0\n",
        "\n",
        "        if similarity > best_similarity:\n",
        "            best_similarity = similarity\n",
        "            best_match = known_med\n",
        "\n",
        "    if best_similarity >= threshold:\n",
        "        st.info(f\"Match simple: '{detected_text}' ‚Üí '{best_match}' (similarit√©: {best_similarity:.2f})\")\n",
        "        return best_match\n",
        "\n",
        "    return None\n",
        "\n",
        "def find_semantic_match(detected_text, known_medications, sentence_model, threshold=0.6):\n",
        "    \"\"\"Trouve le meilleur match s√©mantique\"\"\"\n",
        "    try:\n",
        "        # Cr√©er les embeddings\n",
        "        detected_embedding = sentence_model.encode([detected_text])\n",
        "        known_embeddings = sentence_model.encode(list(known_medications))\n",
        "\n",
        "        # Calculer les similarit√©s cosinus\n",
        "        similarities = cosine_similarity(detected_embedding, known_embeddings)[0]\n",
        "\n",
        "        # Trouver le meilleur match\n",
        "        best_idx = np.argmax(similarities)\n",
        "        best_similarity = similarities[best_idx]\n",
        "        best_match = list(known_medications.keys())[best_idx]\n",
        "\n",
        "        if best_similarity >= threshold:\n",
        "            st.info(f\"Match s√©mantique: '{detected_text}' ‚Üí '{best_match}' (confiance: {best_similarity:.2f})\")\n",
        "            return best_match\n",
        "        else:\n",
        "            st.warning(f\"Similarit√© faible ({best_similarity:.2f}) pour '{detected_text}' ‚Üí '{best_match}'\")\n",
        "            return best_match  # Retourner quand m√™me le meilleur match m√™me si faible\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Erreur matching s√©mantique: {e}\")\n",
        "        return detected_text\n",
        "\n",
        "def find_best_match(detected_text, known_medications, sentence_model, threshold=0.6):\n",
        "    \"\"\"Trouve le meilleur match avec maximisation de la ressemblance caract√®re par caract√®re\"\"\"\n",
        "    try:\n",
        "        if not detected_text:\n",
        "            return None\n",
        "\n",
        "        # Nettoyer le texte d√©tect√©\n",
        "        cleaned_text = enhanced_clean_medication_text(detected_text)\n",
        "\n",
        "        # Si le texte nettoy√© est vide\n",
        "        if not cleaned_text:\n",
        "            return None\n",
        "\n",
        "        # 1. V√©rifier d'abord les correspondances exactes\n",
        "        for known_med in known_medications:\n",
        "            if known_med == cleaned_text:\n",
        "                return known_med\n",
        "\n",
        "        # 2. Correspondances partielles (un m√©dicament contient l'autre ou vice versa)\n",
        "        for known_med in known_medications:\n",
        "            if known_med in cleaned_text or cleaned_text in known_med:\n",
        "                st.info(f\"Correspondance partielle: '{cleaned_text}' ‚Üí '{known_med}'\")\n",
        "                return known_med\n",
        "\n",
        "        # 3. Similarit√© de Levenshtein (distance d'√©dition) pour ressemblance caract√®re par caract√®re\n",
        "        best_levenshtein_match = find_levenshtein_match(cleaned_text, known_medications)\n",
        "        if best_levenshtein_match:\n",
        "            return best_levenshtein_match\n",
        "\n",
        "        # 4. Similarit√© s√©mantique avec Sentence-BERT (fallback)\n",
        "        if sentence_model is not None:\n",
        "            return find_semantic_match(cleaned_text, known_medications, sentence_model, threshold)\n",
        "\n",
        "        # 5. Si rien ne marche, retourner le texte nettoy√©\n",
        "        return cleaned_text\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Erreur dans le matching: {e}\")\n",
        "        return enhanced_clean_medication_text(detected_text)\n",
        "\n",
        "def map_to_standard_medication(detected_text, sentence_model):\n",
        "    \"\"\"Mappe le texte d√©tect√© vers des noms standardis√©s de m√©dicaments\"\"\"\n",
        "    return find_best_match(detected_text, COMMON_MEDICATIONS, sentence_model)\n",
        "\n",
        "# --- 7Ô∏è‚É£ D√©tection et reconnaissance compl√®te ---\n",
        "def detect_and_recognize_medications(image, yolo_model, trocr_processor, trocr_model, sentence_model):\n",
        "    \"\"\"D√©tecte les m√©dicaments avec YOLO et extrait le texte avec TrOCR\"\"\"\n",
        "    detected_medications = []\n",
        "\n",
        "    try:\n",
        "        # D√©tection YOLO\n",
        "        results = yolo_model.predict(source=image, conf=0.5, save=False)\n",
        "\n",
        "        # Image pour dessiner les bounding boxes\n",
        "        draw_img = image.copy()\n",
        "        draw = ImageDraw.Draw(draw_img)\n",
        "\n",
        "        for r in results:\n",
        "            boxes = r.boxes.xyxy.cpu().numpy()\n",
        "            confidences = r.boxes.conf.cpu().numpy()\n",
        "\n",
        "            for i, (box, conf) in enumerate(zip(boxes, confidences)):\n",
        "                x1, y1, x2, y2 = map(int, box)\n",
        "\n",
        "                # Dessiner la bounding box\n",
        "                draw.rectangle([x1, y1, x2, y2], outline=\"red\", width=3)\n",
        "                draw.text((x1, y1-10), f\"Med {i+1} ({conf:.2f})\", fill=\"red\")\n",
        "\n",
        "                # Extraire la r√©gion d'int√©r√™t (ROI)\n",
        "                roi = image.crop((x1, y1, x2, y2))\n",
        "\n",
        "                # OCR avec TrOCR\n",
        "                if trocr_processor and trocr_model:\n",
        "                    extracted_text = extract_text_with_trocr(trocr_processor, trocr_model, roi)\n",
        "                else:\n",
        "                    # Fallback: simulation\n",
        "                    extracted_text = f\"MEDICAMENT_{i+1}\"\n",
        "\n",
        "                if extracted_text:\n",
        "                    # Afficher le texte OCR brut d√©tect√©\n",
        "                    st.info(f\"üìù Texte OCR brut d√©tect√©: '{extracted_text}'\")\n",
        "\n",
        "                    # Mapping vers un m√©dicament standard\n",
        "                    mapped_med = map_to_standard_medication(extracted_text, sentence_model)\n",
        "\n",
        "                    if mapped_med:\n",
        "                        detected_medications.append({\n",
        "                            'original_text': extracted_text,\n",
        "                            'mapped_med': mapped_med,\n",
        "                            'confidence': conf,\n",
        "                            'bbox': (x1, y1, x2, y2)\n",
        "                        })\n",
        "\n",
        "        return detected_medications, draw_img\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Erreur lors de la d√©tection: {e}\")\n",
        "        # Simulation de fallback\n",
        "        simulated_meds = [\n",
        "            {'original_text': 'PARACETAMOL', 'mapped_med': 'PARACETAMOL', 'confidence': 0.95, 'bbox': (50, 50, 200, 100)},\n",
        "            {'original_text': 'METFORMINE', 'mapped_med': 'METFORMINE', 'confidence': 0.92, 'bbox': (50, 150, 200, 200)}\n",
        "        ]\n",
        "        return simulated_meds, image\n",
        "\n",
        "# --- 8Ô∏è‚É£ Pr√©diction des effets secondaires ---\n",
        "def predict_side_effects(medications, age, sex, blender_model, min_predictions=5):\n",
        "    \"\"\"Pr√©dit les effets secondaires bas√©s sur les m√©dicaments\"\"\"\n",
        "    try:\n",
        "        # Pr√©paration des features\n",
        "        patient_features = {}\n",
        "\n",
        "        # Encodage des m√©dicaments\n",
        "        drugs_up = [med.upper() for med in medications]\n",
        "        for drug in blender_model.top_drugs:\n",
        "            patient_features[f\"drug_{drug}\"] = 1 if drug in drugs_up else 0\n",
        "\n",
        "        # Autres features\n",
        "        patient_features[\"age\"] = age\n",
        "        patient_features[\"sex\"] = sex\n",
        "        patient_features[\"nb_drugs\"] = len(medications)\n",
        "        patient_features[\"nb_reactions\"] = 0\n",
        "        patient_features[\"is_sider\"] = 0\n",
        "\n",
        "        # Cr√©ation du DataFrame\n",
        "        patient_df = pd.DataFrame([patient_features])\n",
        "\n",
        "        # Assurer toutes les colonnes n√©cessaires\n",
        "        for col in blender_model.feature_names:\n",
        "            if col not in patient_df.columns:\n",
        "                patient_df[col] = 0\n",
        "        patient_df = patient_df[blender_model.feature_names]\n",
        "\n",
        "        # Pr√©diction (simulation si mod√®le de d√©mo)\n",
        "        if hasattr(blender_model, 'predict'):\n",
        "            preds, probas = blender_model.predict(patient_df, min_predictions=min_predictions)\n",
        "        else:\n",
        "            # Simulation pour le mod√®le de d√©monstration\n",
        "            np.random.seed(hash(str(medications)) % 10000)\n",
        "            probas = np.random.uniform(0, 0.3, (1, len(blender_model.top_reactions)))\n",
        "            preds = (probas > 0.15).astype(int)\n",
        "\n",
        "            # Assurer le nombre minimum de pr√©dictions\n",
        "            if preds.sum() < min_predictions:\n",
        "                sorted_idx = np.argsort(-probas[0])\n",
        "                for idx in sorted_idx:\n",
        "                    if preds[0, idx] == 0:\n",
        "                        preds[0, idx] = 1\n",
        "                    if preds.sum() >= min_predictions:\n",
        "                        break\n",
        "\n",
        "        # Formatage des r√©sultats\n",
        "        results_list = []\n",
        "        for i, reaction in enumerate(blender_model.top_reactions):\n",
        "            if preds[0, i] == 1:\n",
        "                prob = probas[0][i]\n",
        "                confidence = 'üî¥ HAUTE' if prob > 0.7 else 'üü° MOYENNE' if prob > 0.4 else 'üü¢ FAIBLE'\n",
        "                results_list.append({\n",
        "                    'reaction': reaction,\n",
        "                    'probability': float(prob),\n",
        "                    'confidence': confidence\n",
        "                })\n",
        "\n",
        "        results_list.sort(key=lambda x: x['probability'], reverse=True)\n",
        "        return results_list, patient_df\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Erreur lors de la pr√©diction: {e}\")\n",
        "        return [], None\n",
        "\n",
        "# --- 9Ô∏è‚É£ Analyse SHAP ---\n",
        "def analyze_with_shap(blender_model, patient_df, selected_reaction):\n",
        "    \"\"\"Analyse SHAP pour expliquer la pr√©diction d'une r√©action sp√©cifique\"\"\"\n",
        "    try:\n",
        "        # V√©rifier que le mod√®le a les attributs n√©cessaires\n",
        "        if not hasattr(blender_model, 'base_models') or 'rf1' not in blender_model.base_models:\n",
        "            st.warning(\"Mod√®le incompatible pour l'analyse SHAP\")\n",
        "            return None\n",
        "\n",
        "        # Trouver l'index de la r√©action\n",
        "        if selected_reaction not in blender_model.top_reactions:\n",
        "            st.warning(f\"R√©action '{selected_reaction}' non trouv√©e dans le mod√®le\")\n",
        "            return None\n",
        "\n",
        "        reaction_idx = blender_model.top_reactions.index(selected_reaction)\n",
        "\n",
        "        # Obtenir le classifieur Random Forest pour cette r√©action\n",
        "        rf_classifier = blender_model.base_models['rf1'].estimators_[reaction_idx]\n",
        "\n",
        "        # Cr√©er l'explainer SHAP\n",
        "        explainer = shap.TreeExplainer(rf_classifier)\n",
        "\n",
        "        # Calculer les valeurs SHAP\n",
        "        shap_values = explainer.shap_values(patient_df)\n",
        "\n",
        "        # G√©rer diff√©rents formats de sortie SHAP\n",
        "        if isinstance(shap_values, list):\n",
        "            # Cas multi-classes: prendre les valeurs pour la classe positive\n",
        "            if len(shap_values) == 2:\n",
        "                shap_vals = shap_values[1]  # Classe positive\n",
        "            else:\n",
        "                shap_vals = shap_values[0]\n",
        "        else:\n",
        "            shap_vals = shap_values\n",
        "\n",
        "        # S'assurer que c'est un array 1D\n",
        "        if len(shap_vals.shape) > 1:\n",
        "            shap_vals = shap_vals.flatten()\n",
        "\n",
        "        return {\n",
        "            'explainer': explainer,\n",
        "            'shap_values': shap_vals,\n",
        "            'expected_value': explainer.expected_value[1] if isinstance(explainer.expected_value, (list, np.ndarray)) else explainer.expected_value\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Erreur lors de l'analyse SHAP: {e}\")\n",
        "        return None\n",
        "\n",
        "def plot_shap_analysis(shap_results, patient_df, feature_names):\n",
        "    \"\"\"Cr√©e un graphique SHAP pour visualiser les contributions\"\"\"\n",
        "    try:\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "        # Cr√©er un DataFrame pour les features et leurs contributions\n",
        "        contributions = []\n",
        "        for i, feature in enumerate(feature_names):\n",
        "            contributions.append({\n",
        "                'feature': feature,\n",
        "                'contribution': shap_results['shap_values'][i],\n",
        "                'value': patient_df[feature].iloc[0]\n",
        "            })\n",
        "\n",
        "        contrib_df = pd.DataFrame(contributions)\n",
        "\n",
        "        # S√©parer les contributions positives et n√©gatives\n",
        "        positive_contrib = contrib_df[contrib_df['contribution'] > 0].nlargest(5, 'contribution')\n",
        "        negative_contrib = contrib_df[contrib_df['contribution'] < 0].nsmallest(5, 'contribution')\n",
        "\n",
        "        # Pr√©parer les donn√©es pour le graphique\n",
        "        features_plot = []\n",
        "        values_plot = []\n",
        "        colors_plot = []\n",
        "\n",
        "        for _, row in positive_contrib.iterrows():\n",
        "            features_plot.append(f\"{row['feature']}\\n(valeur: {row['value']})\")\n",
        "            values_plot.append(row['contribution'])\n",
        "            colors_plot.append('red')\n",
        "\n",
        "        for _, row in negative_contrib.iterrows():\n",
        "            features_plot.append(f\"{row['feature']}\\n(valeur: {row['value']})\")\n",
        "            values_plot.append(row['contribution'])\n",
        "            colors_plot.append('blue')\n",
        "\n",
        "        # Cr√©er le graphique √† barres\n",
        "        y_pos = np.arange(len(features_plot))\n",
        "        bars = ax.barh(y_pos, values_plot, color=colors_plot, alpha=0.7)\n",
        "\n",
        "        # Ajouter les √©tiquettes\n",
        "        ax.set_yticks(y_pos)\n",
        "        ax.set_yticklabels(features_plot, fontsize=10)\n",
        "        ax.set_xlabel('Contribution SHAP', fontsize=12)\n",
        "        ax.set_title('Facteurs influen√ßant la pr√©diction', fontsize=14, fontweight='bold')\n",
        "\n",
        "        # Ajouter une l√©gende\n",
        "        ax.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
        "\n",
        "        # Am√©liorer le layout\n",
        "        plt.tight_layout()\n",
        "\n",
        "        return fig\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Erreur lors de la cr√©ation du graphique SHAP: {e}\")\n",
        "        return None\n",
        "\n",
        "def create_shap_summary(shap_results, patient_df, selected_reaction):\n",
        "    \"\"\"Cr√©e un r√©sum√© textuel de l'analyse SHAP\"\"\"\n",
        "    try:\n",
        "        if shap_results is None:\n",
        "            return \"Analyse SHAP non disponible\"\n",
        "\n",
        "        contributions = []\n",
        "        for i, feature in enumerate(patient_df.columns):\n",
        "            contribution = shap_results['shap_values'][i]\n",
        "            value = patient_df[feature].iloc[0]\n",
        "\n",
        "            # Formater le nom de la feature\n",
        "            if feature.startswith('drug_'):\n",
        "                drug_name = feature.replace('drug_', '')\n",
        "                status = \"PR√âSENT\" if value == 1 else \"ABSENT\"\n",
        "                display_name = f\"M√©dicament {drug_name} ({status})\"\n",
        "            elif feature == \"age\":\n",
        "                display_name = f\"√Çge ({int(value)} ans)\"\n",
        "            elif feature == \"sex\":\n",
        "                gender = \"Homme\" if value == 1 else \"Femme\"\n",
        "                display_name = f\"Sexe ({gender})\"\n",
        "            elif feature == \"nb_drugs\":\n",
        "                display_name = f\"Nombre de m√©dicaments ({int(value)})\"\n",
        "            elif feature == \"nb_reactions\":\n",
        "                display_name = f\"Nombre de r√©actions ({int(value)})\"\n",
        "            else:\n",
        "                display_name = feature\n",
        "\n",
        "            contributions.append({\n",
        "                'feature': display_name,\n",
        "                'contribution': contribution,\n",
        "                'value': value\n",
        "            })\n",
        "\n",
        "        contrib_df = pd.DataFrame(contributions)\n",
        "\n",
        "        # G√©n√©rer le r√©sum√©\n",
        "        summary = f\"## üîç Analyse SHAP pour: {selected_reaction}\\n\\n\"\n",
        "\n",
        "        # Facteurs qui augmentent le risque\n",
        "        positive_factors = contrib_df[contrib_df['contribution'] > 0.001].nlargest(3, 'contribution')\n",
        "        if len(positive_factors) > 0:\n",
        "            summary += \"### ‚ûï Facteurs augmentant le risque:\\n\"\n",
        "            for _, factor in positive_factors.iterrows():\n",
        "                summary += f\"- **{factor['feature']}**: +{factor['contribution']:.3f}\\n\"\n",
        "\n",
        "        # Facteurs qui r√©duisent le risque\n",
        "        negative_factors = contrib_df[contrib_df['contribution'] < -0.001].nsmallest(3, 'contribution')\n",
        "        if len(negative_factors) > 0:\n",
        "            summary += \"\\n### ‚ûñ Facteurs r√©duisant le risque:\\n\"\n",
        "            for _, factor in negative_factors.iterrows():\n",
        "                summary += f\"- **{factor['feature']}**: {factor['contribution']:.3f}\\n\"\n",
        "\n",
        "        # Probabilit√© de base\n",
        "        if 'expected_value' in shap_results:\n",
        "            summary += f\"\\n### üìä M√©triques:\\n\"\n",
        "            summary += f\"- **Probabilit√© de base**: {shap_results['expected_value']:.3f}\\n\"\n",
        "            summary += f\"- **Impact total**: {sum(shap_results['shap_values']):.3f}\\n\"\n",
        "\n",
        "        return summary\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Erreur lors de la g√©n√©ration du r√©sum√© SHAP: {e}\"\n",
        "\n",
        "# --- üîü Exemples pr√©d√©finis ---\n",
        "PREDEFINED_EXAMPLES = {\n",
        "    \"Diab√®te (Metformine + Insuline)\": {\n",
        "        \"medications\": [\"METFORMINE\", \"INSULIN\"],\n",
        "        \"age\": 52,\n",
        "        \"sex\": 1,\n",
        "        \"description\": \"Patient diab√©tique sous insulinoth√©rapie\"\n",
        "    },\n",
        "    \"Ob√©sit√© (Zepbound)\": {\n",
        "        \"medications\": [\"ZEPBOUND\"],\n",
        "        \"age\": 42,\n",
        "        \"sex\": 2,\n",
        "        \"description\": \"Traitement pour perte de poids\"\n",
        "    },\n",
        "    \"Douleurs (Parac√©tamol)\": {\n",
        "        \"medications\": [\"PARACETAMOL\"],\n",
        "        \"age\": 35,\n",
        "        \"sex\": 1,\n",
        "        \"description\": \"Antalgique courant\"\n",
        "    },\n",
        "    \"Hypertension (Bisoprolol + Atorvastatine)\": {\n",
        "        \"medications\": [\"BISOPROLOL\", \"ATORVASTATINE\"],\n",
        "        \"age\": 65,\n",
        "        \"sex\": 1,\n",
        "        \"description\": \"Traitement cardiovasculaire\"\n",
        "    },\n",
        "    \"Infection (Amoxicilline)\": {\n",
        "        \"medications\": [\"AMOXICILLINE\"],\n",
        "        \"age\": 28,\n",
        "        \"sex\": 2,\n",
        "        \"description\": \"Antibiotique pour infection\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# --- INTERFACE STREAMLIT ---\n",
        "st.title(\"üíä D√©tection de M√©dicaments & Pr√©diction d'Effets Secondaires\")\n",
        "\n",
        "# Charger les mod√®les\n",
        "blender_model = load_side_effect_model()\n",
        "yolo_model, trocr_processor, trocr_model, sentence_model = load_vision_models()\n",
        "\n",
        "# Sidebar pour les param√®tres\n",
        "st.sidebar.header(\"Param√®tres du Patient\")\n",
        "\n",
        "age = st.sidebar.number_input(\"√Çge\", min_value=1, max_value=120, value=45)\n",
        "sex = st.sidebar.selectbox(\"Sexe\", options=[1, 2], format_func=lambda x: \"Homme\" if x == 1 else \"Femme\")\n",
        "min_predictions = st.sidebar.slider(\"Nombre minimum d'effets √† pr√©dire\", 1, 15, 5)\n",
        "\n",
        "# Onglets principaux\n",
        "tab1, tab2, tab3 = st.tabs([\"üì∑ Analyse d'Image\", \"üíä Saisie Manuelle\", \"üìã Exemples Pr√©d√©finis\"])\n",
        "\n",
        "with tab1:\n",
        "    st.header(\"Analyse d'Image par Cam√©ra/Upload\")\n",
        "\n",
        "    uploaded_file = st.file_uploader(\"Choisir une image de m√©dicaments...\",\n",
        "                                   type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "    col1, col2 = st.columns(2)\n",
        "\n",
        "    detected_medications = []\n",
        "\n",
        "    with col1:\n",
        "        if uploaded_file:\n",
        "            image = Image.open(uploaded_file).convert(\"RGB\")\n",
        "            st.image(image, caption=\"Image upload√©e\", use_container_width=True)\n",
        "\n",
        "            if st.button(\"üîç Analyser l'Image\", type=\"primary\"):\n",
        "                with st.spinner(\"D√©tection et reconnaissance des m√©dicaments en cours...\"):\n",
        "                    if yolo_model is not None:\n",
        "                        # D√©tection et reconnaissance compl√®te\n",
        "                        detected_results, annotated_image = detect_and_recognize_medications(\n",
        "                            image, yolo_model, trocr_processor, trocr_model, sentence_model\n",
        "                        )\n",
        "\n",
        "                        # Afficher l'image annot√©e\n",
        "                        st.image(annotated_image, caption=\"M√©dicaments d√©tect√©s\", use_container_width=True)\n",
        "\n",
        "                        # Afficher les r√©sultats de d√©tection\n",
        "                        if detected_results:\n",
        "                            st.subheader(\"üìã R√©sultats de la Reconnaissance\")\n",
        "\n",
        "                            for i, detection in enumerate(detected_results, 1):\n",
        "                                col_a, col_b, col_c = st.columns([2, 1, 1])\n",
        "                                with col_a:\n",
        "                                    st.write(f\"**{i}. {detection['mapped_med']}**\")\n",
        "                                with col_b:\n",
        "                                    st.write(f\"Conf: {detection['confidence']:.2f}\")\n",
        "                                with col_c:\n",
        "                                    if detection['original_text'] != detection['mapped_med']:\n",
        "                                        st.info(f\"OCR: '{detection['original_text']}'\")\n",
        "\n",
        "                            # Stocker les m√©dicaments mapp√©s pour la pr√©diction\n",
        "                            detected_medications = [det['mapped_med'] for det in detected_results]\n",
        "                            st.session_state.detected_meds = detected_medications\n",
        "                            st.session_state.detection_details = detected_results\n",
        "\n",
        "                        else:\n",
        "                            st.warning(\"Aucun m√©dicament d√©tect√© dans l'image.\")\n",
        "                            st.session_state.detected_meds = []\n",
        "\n",
        "                    else:\n",
        "                        # Mode simulation\n",
        "                        st.info(\"Mode simulation - D√©tection simul√©e\")\n",
        "                        simulated_meds = [\"PARACETAMOL\", \"METFORMINE\"]\n",
        "                        st.session_state.detected_meds = simulated_meds\n",
        "                        for med in simulated_meds:\n",
        "                            st.success(f\"‚úÖ {med}\")\n",
        "\n",
        "    with col2:\n",
        "        if 'detected_meds' in st.session_state and st.session_state.detected_meds:\n",
        "            st.subheader(\"üîÆ Effets Secondaires Pr√©dits\")\n",
        "\n",
        "            results, patient_df = predict_side_effects(\n",
        "                st.session_state.detected_meds,\n",
        "                age, sex, blender_model, min_predictions\n",
        "            )\n",
        "\n",
        "            if results:\n",
        "                st.metric(\"Nombre d'effets d√©tect√©s\", len(results))\n",
        "\n",
        "                # Afficher les pr√©dictions\n",
        "                for i, pred in enumerate(results[:10], 1):\n",
        "                    with st.container():\n",
        "                        col_a, col_b = st.columns([3, 1])\n",
        "                        with col_a:\n",
        "                            st.write(f\"**{i}. {pred['reaction']}**\")\n",
        "                        with col_b:\n",
        "                            st.write(f\"{pred['probability']:.1%} {pred['confidence']}\")\n",
        "                        st.progress(pred['probability'])\n",
        "\n",
        "                # Section SHAP\n",
        "                st.subheader(\"üîç Analyse SHAP\")\n",
        "                if len(results) > 0:\n",
        "                    selected_reaction = st.selectbox(\n",
        "                        \"Choisir une r√©action √† analyser:\",\n",
        "                        options=[r['reaction'] for r in results[:5]],\n",
        "                        key=\"shap_selection_tab1\"\n",
        "                    )\n",
        "\n",
        "                    if selected_reaction and patient_df is not None:\n",
        "                        with st.spinner(\"Analyse SHAP en cours...\"):\n",
        "                            shap_results = analyze_with_shap(blender_model, patient_df, selected_reaction)\n",
        "\n",
        "                            if shap_results is not None:\n",
        "                                # Afficher le r√©sum√© textuel\n",
        "                                shap_summary = create_shap_summary(shap_results, patient_df, selected_reaction)\n",
        "                                st.markdown(shap_summary)\n",
        "\n",
        "                                # Afficher le graphique\n",
        "                                shap_plot = plot_shap_analysis(shap_results, patient_df, patient_df.columns.tolist())\n",
        "                                if shap_plot is not None:\n",
        "                                    st.pyplot(shap_plot)\n",
        "            else:\n",
        "                st.info(\"Aucun effet secondaire significatif pr√©dit.\")\n",
        "\n",
        "with tab2:\n",
        "    st.header(\"Saisie Manuelle des M√©dicaments\")\n",
        "\n",
        "    manual_meds = st.text_area(\n",
        "        \"Entrez les noms des m√©dicaments (un par ligne)\",\n",
        "        placeholder=\"METFORMINE\\nINSULIN\\nPARACETAMOL\",\n",
        "        height=100\n",
        "    )\n",
        "\n",
        "    if st.button(\"Pr√©dire les Effets Secondaires\", key=\"manual_predict\"):\n",
        "        if manual_meds:\n",
        "            medications = [med.strip().upper() for med in manual_meds.split('\\n') if med.strip()]\n",
        "\n",
        "            # Nettoyage et mapping\n",
        "            cleaned_meds = []\n",
        "            for med in medications:\n",
        "                mapped = map_to_standard_medication(med, sentence_model)\n",
        "                cleaned_meds.append(mapped)\n",
        "                if mapped != med:\n",
        "                    st.info(f\"'{med}' ‚Üí '{mapped}'\")\n",
        "\n",
        "            st.write(\"**M√©dicaments analys√©s:**\", \", \".join(cleaned_meds))\n",
        "\n",
        "            results, patient_df = predict_side_effects(cleaned_meds, age, sex, blender_model, min_predictions)\n",
        "\n",
        "            if results:\n",
        "                st.subheader(\"üîÆ Effets Secondaires Pr√©dits\")\n",
        "                st.metric(\"Nombre d'effets d√©tect√©s\", len(results))\n",
        "\n",
        "                # Afficher les pr√©dictions\n",
        "                for i, pred in enumerate(results[:10], 1):\n",
        "                    with st.container():\n",
        "                        col_a, col_b = st.columns([3, 1])\n",
        "                        with col_a:\n",
        "                            st.write(f\"**{i}. {pred['reaction']}**\")\n",
        "                        with col_b:\n",
        "                            st.write(f\"{pred['probability']:.1%} {pred['confidence']}\")\n",
        "                        st.progress(pred['probability'])\n",
        "\n",
        "                # Section SHAP\n",
        "                st.subheader(\"üîç Analyse SHAP\")\n",
        "                if len(results) > 0:\n",
        "                    selected_reaction = st.selectbox(\n",
        "                        \"Choisir une r√©action √† analyser:\",\n",
        "                        options=[r['reaction'] for r in results[:5]],\n",
        "                        key=\"shap_selection_tab2\"\n",
        "                    )\n",
        "\n",
        "                    if selected_reaction and patient_df is not None:\n",
        "                        with st.spinner(\"Analyse SHAP en cours...\"):\n",
        "                            shap_results = analyze_with_shap(blender_model, patient_df, selected_reaction)\n",
        "\n",
        "                            if shap_results is not None:\n",
        "                                # Afficher le r√©sum√© textuel\n",
        "                                shap_summary = create_shap_summary(shap_results, patient_df, selected_reaction)\n",
        "                                st.markdown(shap_summary)\n",
        "\n",
        "                                # Afficher le graphique\n",
        "                                shap_plot = plot_shap_analysis(shap_results, patient_df, patient_df.columns.tolist())\n",
        "                                if shap_plot is not None:\n",
        "                                    st.pyplot(shap_plot)\n",
        "            else:\n",
        "                st.warning(\"Aucun effet secondaire significatif pr√©dit pour cette combinaison.\")\n",
        "\n",
        "with tab3:\n",
        "    st.header(\"Exemples Pr√©d√©finis\")\n",
        "\n",
        "    selected_example = st.selectbox(\"Choisir un exemple\", list(PREDEFINED_EXAMPLES.keys()))\n",
        "\n",
        "    if selected_example:\n",
        "        example_data = PREDEFINED_EXAMPLES[selected_example]\n",
        "\n",
        "        st.write(f\"**Description:** {example_data['description']}\")\n",
        "        st.write(f\"**M√©dicaments:** {', '.join(example_data['medications'])}\")\n",
        "        st.write(f\"**√Çge:** {example_data['age']} ans\")\n",
        "        st.write(f\"**Sexe:** {'Homme' if example_data['sex'] == 1 else 'Femme'}\")\n",
        "\n",
        "        if st.button(\"Lancer la Pr√©diction\", key=\"example_predict\"):\n",
        "            results, patient_df = predict_side_effects(\n",
        "                example_data['medications'],\n",
        "                example_data['age'],\n",
        "                example_data['sex'],\n",
        "                blender_model,\n",
        "                min_predictions\n",
        "            )\n",
        "\n",
        "            if results:\n",
        "                st.subheader(\"üìä R√©sultats de Pr√©diction\")\n",
        "                st.metric(\"Nombre d'effets d√©tect√©s\", len(results))\n",
        "\n",
        "                # Afficher les pr√©dictions\n",
        "                for i, pred in enumerate(results[:10], 1):\n",
        "                    with st.container():\n",
        "                        col_a, col_b = st.columns([3, 1])\n",
        "                        with col_a:\n",
        "                            st.write(f\"**{i}. {pred['reaction']}**\")\n",
        "                        with col_b:\n",
        "                            st.write(f\"{pred['probability']:.1%} {pred['confidence']}\")\n",
        "                        st.progress(pred['probability'])\n",
        "\n",
        "                # Section SHAP\n",
        "                st.subheader(\"üîç Analyse SHAP\")\n",
        "                if len(results) > 0:\n",
        "                    selected_reaction = st.selectbox(\n",
        "                        \"Choisir une r√©action √† analyser:\",\n",
        "                        options=[r['reaction'] for r in results[:5]],\n",
        "                        key=\"shap_selection_tab3\"\n",
        "                    )\n",
        "\n",
        "                    if selected_reaction and patient_df is not None:\n",
        "                        with st.spinner(\"Analyse SHAP en cours...\"):\n",
        "                            shap_results = analyze_with_shap(blender_model, patient_df, selected_reaction)\n",
        "\n",
        "                            if shap_results is not None:\n",
        "                                # Afficher le r√©sum√© textuel\n",
        "                                shap_summary = create_shap_summary(shap_results, patient_df, selected_reaction)\n",
        "                                st.markdown(shap_summary)\n",
        "\n",
        "                                # Afficher le graphique\n",
        "                                shap_plot = plot_shap_analysis(shap_results, patient_df, patient_df.columns.tolist())\n",
        "                                if shap_plot is not None:\n",
        "                                    st.pyplot(shap_plot)\n",
        "\n",
        "                # Graphique des probabilit√©s\n",
        "                if len(results) > 0:\n",
        "                    chart_data = pd.DataFrame({\n",
        "                        'Effets Secondaires': [pred['reaction'] for pred in results[:8]],\n",
        "                        'Probabilit√©': [pred['probability'] for pred in results[:8]]\n",
        "                    })\n",
        "                    st.bar_chart(chart_data, x='Effets Secondaires', y='Probabilit√©')\n",
        "\n",
        "# Footer\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"*Syst√®me de pr√©diction des effets secondaires - √Ä des fins √©ducatives seulement*\")\n",
        "\n",
        "# Information de d√©bogage\n",
        "with st.sidebar:\n",
        "    st.markdown(\"---\")\n",
        "    st.markdown(\"**Informations techniques:**\")\n",
        "    st.write(f\"M√©dicaments connus: {len(blender_model.top_drugs)}\")\n",
        "    st.write(f\"Effets secondaires: {len(blender_model.top_reactions)}\")\n",
        "    st.write(f\"YOLO charg√©: {yolo_model is not None}\")\n",
        "    st.write(f\"TrOCR charg√©: {trocr_model is not None}\")\n",
        "    st.write(f\"Embeddings charg√©s: {sentence_model is not None}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNdCBfWFHV_q",
        "outputId": "0d408a5d-9011-4cb6-ce3e-9fb3f3ddc4fd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting streamlit_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uZQSqRjsLUqe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc65a0df-e33e-4e93-fa09-842c80d3da00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéØ Application accessible √†: NgrokTunnel: \"https://ecdba8a7de4b.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ],
      "source": [
        "# Installation des d√©pendances\n",
        "!pip install --quiet streamlit ultralytics transformers torch pillow pyngrok scikit-learn==1.7.2 xgboost\n",
        "\n",
        "# V√©rifier que le fichier mod√®le est pr√©sent\n",
        "import os\n",
        "if not os.path.exists(\"/content/drive/MyDrive/blender_final_per_label_thresholds (1).pkl\"):\n",
        "    print(\"‚ö†Ô∏è  Fichier mod√®le non trouv√©, l'application fonctionnera en mode d√©monstration\")\n",
        "\n",
        "# Lancer Streamlit\n",
        "from pyngrok import ngrok\n",
        "import threading\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "def run_streamlit():\n",
        "    subprocess.run([\"streamlit\", \"run\", \"streamlit_app.py\", \"--server.port\", \"8501\", \"--server.address\", \"0.0.0.0\"])\n",
        "\n",
        "# D√©marrer dans un thread\n",
        "thread = threading.Thread(target=run_streamlit)\n",
        "thread.daemon = True\n",
        "thread.start()\n",
        "\n",
        "time.sleep(8)  # Attendre que Streamlit d√©marre\n",
        "\n",
        "# Cr√©er le tunnel ngrok\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"üéØ Application accessible √†: {public_url}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8lxIyKZGrpM",
        "outputId": "cfec9e46-a1a2-4116-8476-51cb8100c119"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-10-18T12:19:15+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8501-87a3a02b-8ffa-4157-9816-e92810474999 acceptErr=\"failed to accept connection: Listener closed\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n"
          ]
        }
      ],
      "source": [
        "!pkill -f ngrok && fuser -k 8501/tcp && echo \"‚úÖ Nettoyage termin√©\"\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}